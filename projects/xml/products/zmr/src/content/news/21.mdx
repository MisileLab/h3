---
title: VLM(시각 언어 모델 - Vision Language Model)은 볼 수 없습니다.
createdDate: 1720666612
tldr: 여러 테스트에서 단 한 모델도 모든 서브 테스트 케이스를 통과하지 못합니다.
---
아래 글은 [OpenAI](https://openai.com)의 gpt4o 기반 Jessica로 요약되었습니다.

## [Vision Language Models (VLMs) Performance Study - GitHub](https://vlmsareblind.github.io)
이 문서는 다양한 Vision Language Models (VLMs)의 시각적 과제 수행 능력에 관한 연구를 다룹니다.\
네 개의 모델이 선 교차점 세기, 겹쳐진 원 식별, 원 안에 있는 문자 인식, 겹쳐진 모양 세기, 중첩된 사각형 세기, 격자에서 행과 열 세기 등과 같은 과제에서 테스트되었습니다.\
분석 결과, 이 모델들은 텍스트 기반 과제에서는 뛰어난 성과를 보였으나 인간에게 쉽게 여겨지는 기본적인 시각 인식 과제에서는 어려움을 겪었습니다.\
이 연구는 시각적 이해와 해석이 필요한 작업에서 VLMs의 한계를 강조했습니다.

## [Hacker News Discussion on VLMs Performance - Hacker News](https://news.ycombinator.com/item?id=40926734)
이 포스트는 Hacker News 사용자들이 Vision Language Models (VLMs)와 그 시각적 과제 수행 한계에 대해 논의하는 내용을 담고 있습니다.\
일부 사용자는 그 논문이 모델들의 능력을 잘못 표현하고 있다고 주장하는 반면, 다른 사용자들은 모델이 실패하는 지점을 식별하는 중요성을 강조합니다.\
테스트의 적절성과 모델들이 부당하게 비판받고 있는지 혹은 유효한 우려가 제기되고 있는지에 대한 논쟁도 있습니다.\
또한 OCR 관련 예시와 VLMs의 다양한 응용 가능성에 대한 언급도 있습니다.\
VLMs의 성과를 평가하기 위한 추가 테스트와 고려사항에 대한 추천도 논의됩니다.

[출처](https://news.ycombinator.com/item?id=40926734)
