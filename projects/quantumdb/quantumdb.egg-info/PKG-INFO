Metadata-Version: 2.4
Name: quantumdb
Version: 0.1.0
Summary: High-performance vector database with learnable compression, powered by Qdrant
Author: QuantumDB Team
License: MIT
Project-URL: Homepage, https://github.com/quantumdb/quantumdb
Project-URL: Repository, https://github.com/quantumdb/quantumdb
Project-URL: Documentation, https://quantumdb.readthedocs.io
Project-URL: Bug Tracker, https://github.com/quantumdb/quantumdb/issues
Keywords: vector-database,machine-learning,search,qdrant,pytorch
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Database :: Database Engines/Servers
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.20
Requires-Dist: torch>=2.0
Requires-Dist: optuna>=3.0
Requires-Dist: safetensors>=0.4.1
Requires-Dist: qdrant-client>=1.7.0
Requires-Dist: sentence-transformers>=2.2.0
Requires-Dist: pandas>=1.3.0
Requires-Dist: tqdm>=4.64.0
Requires-Dist: pydantic>=2.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: pre-commit>=3.0.0; extra == "dev"
Provides-Extra: evaluation
Requires-Dist: beir>=1.0.1; extra == "evaluation"
Requires-Dist: wandb>=0.15.0; extra == "evaluation"
Requires-Dist: matplotlib>=3.5.0; extra == "evaluation"
Requires-Dist: seaborn>=0.11.0; extra == "evaluation"
Requires-Dist: jupyter>=1.0.0; extra == "evaluation"
Requires-Dist: notebook>=6.4.0; extra == "evaluation"

# QuantumDB: High-Performance Vector Database with Learnable Compression

QuantumDB is a Python-based vector database that combines learnable compression models with Qdrant's production-grade vector storage. It provides efficient vector search with significant memory savings while maintaining high accuracy.

## ğŸš€ Features

- **Learnable Compression**: Train neural networks to compress vectors while preserving search quality
- **Production-Ready Storage**: Built on Qdrant, a Rust-based vector database with HNSW indexing
- **Flexible Embeddings**: Support for sentence-transformers, OpenAI, Hugging Face, and custom embedders
- **Comprehensive Evaluation**: BEIR benchmark integration and custom metrics
- **Easy Deployment**: Docker Compose setup with one-command deployment
- **High Performance**: Sub-millisecond search latency with millions of vectors

## ğŸ“‹ Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Examples](#examples)
- [API Reference](#api-reference)
- [Performance](#performance)
- [Contributing](#contributing)

## ğŸ› ï¸ Installation

### Using uv (Recommended)

```bash
# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and install QuantumDB
git clone https://github.com/quantumdb/quantumdb.git
cd quantumdb
uv sync
```

### Using pip

```bash
# Clone the repository
git clone https://github.com/quantumdb/quantumdb.git
cd quantumdb

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -e ".[dev,evaluation]"
```

### Docker Deployment

```bash
# Clone and start with Docker Compose
git clone https://github.com/quantumdb/quantumdb.git
cd quantumdb
docker-compose up -d
```

## ğŸƒâ€â™‚ï¸ Quick Start

### 1. Train a Compression Model

```python
import numpy as np
from quantumdb.training import LearnablePQ, Trainer
from quantumdb.data import SyntheticDataGenerator

# Generate synthetic training data
data_generator = SyntheticDataGenerator(random_state=42)
train_vectors = data_generator.generate_text_like_vectors(
    n_samples=100000, dimension=768
)

# Create and train model
model = LearnablePQ(
    input_dim=768,
    target_dim=256,
    n_subvectors=16,
    codebook_size=256,
)

trainer = Trainer(model, experiment_name="my_model")
history = trainer.fit(train_vectors, epochs=50)
```

### 2. Build Vector Index

```python
from quantumdb import QuantumDB

# Initialize database with trained model
db = QuantumDB(
    model_path="models/my_model_best.safetensors",
    collection_name="my_collection",
    vector_size=256,
)

# Add vectors to database
vectors = np.random.randn(10000, 768).astype(np.float32)
ids = list(range(10000))
payloads = [{"title": f"Doc {i}"} for i in range(10000)]

result = db.add(vectors, ids, payloads)
print(f"Added {result['vectors_added']} vectors")
```

### 3. Search Vectors

```python
# Perform similarity search
query_vector = np.random.randn(768).astype(np.float32)
results = db.search(query_vector, limit=10)

for doc_id, score, payload in results:
    print(f"ID: {doc_id}, Score: {score:.4f}, Title: {payload['title']}")
```

## ğŸ—ï¸ Architecture

QuantumDB combines Python's ML ecosystem with Qdrant's production database:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python Layer (Training & API)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ LearnablePQ Model (PyTorch)          â”‚
â”‚ â€¢ Training Pipeline (Optuna)            â”‚
â”‚ â€¢ Data Loading & Embeddings             â”‚
â”‚ â€¢ Evaluation & Benchmarking             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Qdrant Layer (Production Storage)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ HNSW Index (Fast Search)              â”‚
â”‚ â€¢ Vector Compression (PQ)               â”‚
â”‚ â€¢ Filtering & Payloads                  â”‚
â”‚ â€¢ Distributed Deployment                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

- **LearnablePQ**: Neural network-based product quantization
- **QuantumDB API**: Python wrapper for Qdrant with compression
- **Training Pipeline**: Automated hyperparameter tuning with Optuna
- **Evaluation Framework**: BEIR benchmark integration
- **Data Loaders**: Support for MS MARCO, BEIR, and custom datasets

## ğŸ“š Examples

### Training with Custom Data

```python
from quantumdb.data import create_embedder, MSLoader
from quantumdb.training import Trainer, LearnablePQ

# Load MS MARCO dataset
loader = MSLoader("data/ms_marco")
passages, queries, qrels = loader.load_all()

# Generate embeddings
embedder = create_embedder("sentence_transformer", "all-MiniLM-L6-v2")
passage_embeddings = embedder.encode(list(passages.values()))

# Train compression model
model = LearnablePQ(input_dim=384, target_dim=128)
trainer = Trainer(model, use_wandb=True)
history = trainer.fit(passage_embeddings, epochs=100)
```

### Advanced Search with Filtering

```python
# Search with metadata filters
results = db.search(
    query_vector,
    limit=10,
    filter_params={
        "must": [
            {"key": "category", "match": {"value": "technology"}},
            {"key": "date", "range": {"gte": "2023-01-01"}}
        ]
    }
)
```

### Batch Processing

```python
# Batch search for multiple queries
query_vectors = np.random.randn(100, 768)
all_results = []

for query in query_vectors:
    results = db.search(query, limit=5)
    all_results.append(results)
```

### Performance Benchmarking

```python
from quantumdb.evaluation import BenchmarkRunner

# Run comprehensive benchmarks
benchmark = BenchmarkRunner()
metrics = benchmark.benchmark_search_performance(
    db, test_queries, num_queries=1000
)

print(f"QPS: {metrics.queries_per_second:.1f}")
print(f"P95 Latency: {metrics.latency_p95*1000:.2f}ms")
```

## ğŸ”§ API Reference

### QuantumDB Class

```python
class QuantumDB:
    def __init__(
        self,
        model_path: Optional[str] = None,
        qdrant_host: str = "localhost",
        qdrant_port: int = 6333,
        collection_name: str = "quantumdb_collection",
        vector_size: int = 256,
        distance: str = "cosine",
        # ... other parameters
    ):
        """Initialize QuantumDB instance."""
    
    def add(
        self,
        vectors: np.ndarray,
        ids: Optional[List[Union[str, int]]] = None,
        payloads: Optional[List[Dict[str, Any]]] = None,
        batch_size: int = 1000,
    ) -> Dict[str, Any]:
        """Add vectors to the database."""
    
    def search(
        self,
        query_vector: np.ndarray,
        limit: int = 10,
        score_threshold: Optional[float] = None,
        filter_params: Optional[Dict[str, Any]] = None,
        with_payload: bool = True,
    ) -> List[Tuple[Union[str, int], float, Dict[str, Any]]]:
        """Search for similar vectors."""
```

### LearnablePQ Model

```python
class LearnablePQ(nn.Module):
    def __init__(
        self,
        input_dim: int = 768,
        target_dim: int = 256,
        n_subvectors: int = 16,
        codebook_size: int = 256,
    ):
        """Initialize learnable product quantization model."""
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """Forward pass through the model."""
    
    def get_compression_ratio(self) -> float:
        """Calculate compression ratio."""
```

## ğŸ“Š Performance

### Compression Efficiency

| Original Dimension | Compressed Dimension | Compression Ratio | Memory Savings |
|-------------------|---------------------|------------------|----------------|
| 768 (float32)     | 256 (compressed)    | 12x              | 92%            |
| 1536 (float32)    | 256 (compressed)    | 24x              | 96%            |
| 4096 (float32)    | 512 (compressed)    | 32x              | 97%            |

### Search Performance

| Dataset Size | QPS | P95 Latency | Memory Usage |
|-------------|-----|-------------|--------------|
| 100K        | 2,500 | 2.1ms      | 45MB         |
| 1M          | 1,800 | 3.2ms      | 380MB        |
| 10M         | 1,200 | 5.8ms      | 3.2GB        |

### Search Quality

| Model | Recall@10 | NDCG@10 | Compression |
|-------|-----------|---------|-------------|
| Original (768d) | 0.842 | 0.789 | 1x |
| QuantumDB (256d) | 0.821 | 0.768 | 12x |
| Standard PQ (256d) | 0.798 | 0.742 | 12x |

## ğŸ³ Docker Deployment

### Development Environment

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f app

# Stop services
docker-compose down
```

### Production Deployment

```bash
# Use production configuration
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Scale the application
docker-compose up -d --scale app=3
```

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=quantumdb --cov-report=html

# Run specific test file
uv run pytest tests/test_api.py
```

## ğŸ“ˆ Evaluation on BEIR

```python
from quantumdb.evaluation import BEIREvaluator, evaluate_on_beir_datasets

# Evaluate on single dataset
evaluator = BEIREvaluator("nfcorpus")
metrics = evaluator.evaluate_model(model, embedder)

# Evaluate on multiple datasets
datasets = ["trec-covid", "nfcorpus", "nq", "hotpotqa"]
results = evaluate_on_beir_datasets(model, embedder, datasets)
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Clone repository
git clone https://github.com/quantumdb/quantumdb.git
cd quantumdb

# Install development dependencies
uv sync --dev

# Install pre-commit hooks
pre-commit install

# Run linting and formatting
uv run ruff check .
uv run ruff format .
uv run mypy quantumdb/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Qdrant](https://qdrant.tech/) for the high-performance vector database
- [Sentence Transformers](https://www.sbert.net/) for embedding models
- [BEIR](https://github.com/beir-cellar/beir) for evaluation benchmarks
- [PyTorch](https://pytorch.org/) for deep learning framework
- [Optuna](https://optuna.org/) for hyperparameter optimization

## ğŸ“ Support

- ğŸ“– [Documentation](https://quantumdb.readthedocs.io)
- ğŸ› [Issue Tracker](https://github.com/quantumdb/quantumdb/issues)
- ğŸ’¬ [Discussions](https://github.com/quantumdb/quantumdb/discussions)

---

**QuantumDB** - Making vector search efficient and accessible. ğŸš€
